# Summary

We will now summarise your learning on data sourcing, which was covered by this session.

Data is of two main types:

- **Public data:**  This is the data that is made publicly available for the purpose of research and learning.
- **Private data:**  This is organisational data. Organisations have certain security and privacy concerns, and, so, company approval is needed to access such data. It is useful for organisations for internal policymaking and for building business strategies.

![Data_Sourcing](https://i.ibb.co/Zc5vsk0/Data-Sourcing.png)

Here are the links to some public data sets. You may explore these open sources to obtain data:

**GitHub:**  [Awesome public data sets](https://github.com/awesomedata/awesome-public-datasets),  [GitHub data sets](https://github.com/datameet)

**Open government data set:**  [Open government data](https://data.gov.in/)

**Kaggle:** [Kaggle website](https://www.kaggle.com/datasets)

**UCI Repository of Machine Learning:** [UCI machine learning data set repository](https://archive.ics.uci.edu/ml/index.php)

Apart from learning about public and private data sources, you learnt about a data-fetching technique called **web scraping**, which is useful for fetching data directly from web pages. It is used in many applications, such as price comparison in e-commerce, real estate and share market.

Web scraping majorly involves four steps:

- **HTML loading and reading:**  It includes loading the HTML page in Python. The library that is used here to request an HTML page is the “**request**” library.
- **HTML parsing:**  This step involves presenting the HTML code in a readable format. One of the important classes of Python, called “**BeautifulSoup**”, is used here to parse the data.
- **Data extraction:**  This step involves extracting data from the web page using HTML elements like tags and attributes.
- **Transformation into required format:** Once you have the data, you can save it in the required format, for example, CSV.

Data sourcing is the very first step of EDA, and after getting the data in the required file types, we need to clean it. The next session will help you learn the end-to-end process of cleaning a data set with the help of a practical case study.
