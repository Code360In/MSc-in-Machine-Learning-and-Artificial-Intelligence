# Summary

In this module, you learnt about logistic regression. It is a fundamental classification algorithm. Let’s summarise your learnings about the same. 

1.  The fundamentals of logistic regression are as follows:
    
    1.  Sigmoid function: Used to convert ranges into probabilities 
        
    2.  Odds and log odds: Help in interpreting the weightage of the features 
        
    3.  Likelihood function: Helps in measuring the goodness of statistical fit for binary variable distributions
        
    4.  Log loss function: Is the cost function for logistic regression 
        
    5.  Gradient descent: Helps in minimising the log loss function  
         
        
2.  Logistic regression using Python includes the following:
    
    1.  Data cleaning and preparation 
        
    2.  Model building 
        
    3.  Feature selection 
        
    4.  Evaluation metrics, which are as follows: 
        
        1.  Accuracy 
            
        2.  Specificity and sensitivity 
            
        3.  ROC AUC 
            
        4.  Precision and recall  
             
            
3.  Logistic regression using PySpark involves the following:
    
    1.  Data sampling and preparation
        
    2.  Pipeline API 
        
    3.  Model building 
        
    4.  Model improvement 
        
    5.  Cluster management 
        
    6.  Multinomial logistic regression 
        

Whenever you are building a model to solve classification problems, it is always preferable to start with logistic regression. Use logistic regression as the benchmark for a model’s performance. Any other classification model used must perform better than logistic regression. Regularisation is an important concept that was not covered in the module. It can greatly improve the predictability of any model. You will learn about it in the coming module.