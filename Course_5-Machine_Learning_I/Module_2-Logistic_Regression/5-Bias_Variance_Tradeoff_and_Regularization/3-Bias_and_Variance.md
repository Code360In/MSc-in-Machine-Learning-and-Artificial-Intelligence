# Bias and Variance

In the previous segment, you learned about some key concepts known as underfitting, overfitting and model capacity (also known as model complexity). In any supervised learning model, the poor performance or the estimated prediction error can be broken down into the so-called Bias error and Variance error. These concepts are highly related to underfitting and overfitting that you learned in your previous segment. Let us understand what these terms signify.  
 

 In the next video, Jaidev will explain what is meant by Bias.

**VIDEO**

Bias essentially means ‘How far the model is from the optimal position’. Bias quantifies how accurate the model is likely to be on the future (test) data. Extremely simple models are likely to fail in predicting complex real-world phenomena.

Consider the below image with different linear model fits and their corresponding bias values plotted on the right graph.

![Graph 1](https://i.ibb.co/cvc2hN6/Bias-and-Variance-Graph1.png)

As you can see, the line with the lowest bias (red line) corresponds to the most optimal linear fit line compared to all the linear fits presented in the image. However, moving the red line upwards or downwards away from the data results in an increasing bias. However, even the red line is not an optimal fit for this dataset. We say that the linear model has a high bias since it is way too simple to be able to learn the complexity involved in the task.

In the previous segment, you saw that a polynomial fit would be able to capture the sinusoidal nature of the data, and that sort of model is a model with optimal bias, where the predicted values are almost closer to the actual data points making it a model with low bias

High Bias suggests that the model has been generated by considering many assumptions and making the algorithm less complex. Hence, **high bias corresponds to underfitting**. 

In the next video, you will learn about Variance.

**VIDEO**

In this video you learned about Variance. Variance of a model is the ‘tendency of the model to adapt to noise or unseen data’.

The ‘variance’ of a model is the variance (as learnt in inferential statistics) in the output on the same test data with respect to the changes in the training data. In other words, variance here refers to the degree of changes in the model itself with respect to changes in training data.

Consider the following polynomial fit on the dataset (left image) given below.

![Graph 2](https://i.ibb.co/QfdzWB9/Bias-and-Variance-Graph2.png)

If you compare the images on the left and right, you will notice the variance values first increase and decrease with increasing degree of the polynomial. As per the left image, the orange model, or the polynomial of degree 10, it seems like it is the best fit model for this data. However, this polynomial was only able to fit the data that it has seen until now. Given its nature, it fails on fitting it on unseen data as shown in the image below.

![Graph 3](https://i.ibb.co/8jcG95x/Bias-and-Variance-Graph3.png)

Considering the example of the model (shown above), if you change the dataset a little, this model will change drastically. The model is, therefore, unstable and sensitive to changes in training data, and this is called high variance. 

The same would hold true if the model also learns the noise within the data. As you can see, the model has been fitted perfectly on the training data; however, it poorly fits the testing data.

![Graph 4](https://i.ibb.co/PjVMR3S/Bias-and-Variance-Graph4.png)

Since this model is found to capture the unwanted noise within the training data and is overly sensitive to the training data, such a model is said to be overfitting. 

**High variance corresponds to overfitting.** An example of a High Variance algorithm is Decision Trees.

If you notice carefully the graphs containing both bias and variance, you will notice that there is a trade-off between the two, which is known as the bias-variance tradeoff in machine learning. This is where the concepts of bias and variance help us in selecting a good model for our dataset. You will be learning about this tradeoff in detail in the next segment.