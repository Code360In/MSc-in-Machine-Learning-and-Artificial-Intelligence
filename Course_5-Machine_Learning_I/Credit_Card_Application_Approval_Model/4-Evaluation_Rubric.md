# Evaluation Rubric

## Important

**Use PySpark to implement the assignment.** You can use an EC2 instance or EMR cluster to work on the assignment (we recommend using the t2.large EC2 instance). If you are facing any memory issues, you can use an EMR cluster, but ensure that you are not using any higher configuration clusters, to avoid incurring unnecessary costs (Preferable configuration: 2 Node Clusters and 1 master node M4.large and 1 Core node M4.large).

If you are using an EC2 instance, scale the instance when you face memory associated errors. Refer to the Course 1 Assignment if you are unsure about how to scale your EC2 instance.

Some pointers that you must keep in mind while creating your model are given below:

- Use a **train-test split of 70:30** and a seed value of **2018** in your PySpark model.
- As you already know, weak predictors may bias your model, so you can use information value to eliminate them. In this problem, most of the predictors are weak predictors; hence, you can consider predictors with **IV values less than 0.002** to be insignificant in the modelling process.
- Target for a **higher recall**, as the bank is primarily interested in classifying the defaulters correctly.


| **Criteria** | **Meets Expectations** | **Does Not Meet Expectations** |
|---|---|---|
| Data understanding, preparation and EDA (45%) | 1. All data quality checks are performed, and all data quality issues are addressed in the right manner (missing value imputation, removing duplicate data and other types of data redundancies). Explanations for data quality issues are clearly mentioned in comments. <br> 2. Categorical variables are handled appropriately. WOE-IV implementations are performed on the categorical data.  <br> 3. New metrics are derived, if applicable, and are used for analysis and modelling.  <br> 4. The data is converted into a clean format suitable for analysis.  <br> 5. All the EDA steps listed as part of the problem statement are performed, and results are well-summarised in the form of comments.  <br> | 1. All quality checks are not done and data quality issues are not addressed correctly to an appropriate level.  <br> 2. Categorical variables are not handled appropriately wherever required.  <br> 3. New metrics are not derived or used for analysis.  <br> 4. The data is not converted into a clean format suitable for analysis or is not cleaned using commands.  <br> 5. Skipping EDA and directly jumping to model building.  <br> 6. Not performing the EDA steps given on the platform (Refer to the  Problem Statement segment for the relevant EDA). <br> |
| Model building (25%) | Model parameters are tuned using correct principles, and the approach is explained clearly. Both technical aspects and business aspects are considered while building the model.  <br>       Correct variable selection techniques are used. A reasonable number of different models is attempted, and the best one is chosen based on key performance metrics.  <br> | Parameters are not tuned enough or are tuned incorrectly. Relevant business aspects are not considered while building the model.  <br> Variable selection techniques are used incorrectly or are not conducted. A variety of models is not considered, or a suboptimal one is finalised.  <br> |
| Model Evaluation (20%) | Model evaluation is done using the correct principles, and appropriate evaluation metrics are reported.  <br> The results are on par with the best possible model on the data set.  <br>  The model is interpreted and explained correctly. The commented code includes a brief explanation of the important variables and the model in simple terms.  <br> | The evaluation process deviates from correct model selection principles; inappropriate metrics are evaluated or are incorrectly evaluated.  <br> The results are not on par with the best possible model on the data set.  <br> The model is not interpreted and explained correctly.  <br> |
| Coding Guidelines (10%) | Appropriate comments are written wherever applicable.  <br> If new variables are created, the names are descriptive and unambiguous.  <br> The code is written concisely wherever possible.  <br> Overall, code readability is good with appropriate indentations.  <br> A summary report that includes an explanation of the inferences made at each step is submitted. The notebook is running without any errors.  <br>                                | Comments are not written, making the code difficult to understand.         Variables are poorly or ambiguously named.         The code is more complex than what is required according to the problem.          Code readability is poor because of poor indentation or other reasons.         No proper documentation is done, but the notebook executes successfully.   |