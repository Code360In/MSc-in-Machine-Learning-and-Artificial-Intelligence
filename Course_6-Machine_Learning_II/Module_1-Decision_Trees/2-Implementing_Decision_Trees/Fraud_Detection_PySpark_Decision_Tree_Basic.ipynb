{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7be4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk-17.0.4/\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-3.3.0-bin-hadoop3\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.9.5-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd30e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q fsspec\n",
    "!pip3 install -q s3fs\n",
    "!pip3 install -q numpy\n",
    "!pip3 install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f192579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d43722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/25 19:00:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "                            .appName(\"Credit_Card_Applitcation_Approval\") \\\n",
    "                            .config(\"spark.ui.port\", \"4050\") \\\n",
    "                            .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2d6859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: long (nullable = true)\n",
      " |-- isFlaggedFraud: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"s3a://decisiontreespark/fraud_detection_data.csv\", header=\"infer\")\n",
    "data = spark.createDataFrame(df)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91e63bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|   amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT|  9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|    181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|    181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT| 11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7817.71|  C90045638|      53860.0|      46042.29| M573487274|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7107.77| C154988899|     183195.0|     176087.23| M408069119|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7861.64|C1912850431|    176087.23|     168225.59| M633326333|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  4024.36|C1265012928|       2671.0|           0.0|M1176932104|           0.0|           0.0|      0|             0|\n",
      "|   1|   DEBIT|  5337.77| C712410124|      41720.0|      36382.23| C195600860|       41898.0|      40348.79|      0|             0|\n",
      "|   1|   DEBIT|  9644.94|C1900366749|       4465.0|           0.0| C997608398|       10845.0|     157982.12|      0|             0|\n",
      "|   1| PAYMENT|  3099.97| C249177573|      20771.0|      17671.03|M2096539129|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  2560.74|C1648232591|       5070.0|       2509.26| M972865270|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 11633.76|C1716932897|      10127.0|           0.0| M801569151|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  4098.78|C1026483832|     503264.0|     499165.22|M1635378213|           0.0|           0.0|      0|             0|\n",
      "|   1|CASH_OUT|229133.94| C905080434|      15325.0|           0.0| C476402209|        5083.0|      51513.44|      0|             0|\n",
      "|   1| PAYMENT|  1563.82| C761750706|        450.0|           0.0|M1731217984|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  1157.86|C1237762639|      21156.0|      19998.14|M1877062907|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|   671.64|C2033524545|      15123.0|      14451.36| M473053293|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER| 215310.3|C1670993182|        705.0|           0.0|C1100439041|       22425.0|           0.0|      0|             0|\n",
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08194109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['step',\n",
       " 'type',\n",
       " 'amount',\n",
       " 'nameOrig',\n",
       " 'oldbalanceOrg',\n",
       " 'newbalanceOrig',\n",
       " 'nameDest',\n",
       " 'oldbalanceDest',\n",
       " 'newbalanceDest',\n",
       " 'isFraud',\n",
       " 'isFlaggedFraud']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View columns.\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b32c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required columns.\n",
    "sel_cols=[\"step\", \"type\", \"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \n",
    "          \"oldbalanceDest\", \"newbalanceDest\", \"isFraud\", \"isFlaggedFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673519b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe consisting of selected columns.\n",
    "df = data.select(sel_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aae319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+-------------+--------------+--------------+--------------+-------+--------------+\n",
      "|step|    type|   amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+---------+-------------+--------------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT|  9839.64|     170136.0|     160296.36|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  1864.28|      21249.0|      19384.72|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|    181.0|        181.0|           0.0|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|    181.0|        181.0|           0.0|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT| 11668.14|      41554.0|      29885.86|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7817.71|      53860.0|      46042.29|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7107.77|     183195.0|     176087.23|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7861.64|    176087.23|     168225.59|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  4024.36|       2671.0|           0.0|           0.0|           0.0|      0|             0|\n",
      "|   1|   DEBIT|  5337.77|      41720.0|      36382.23|       41898.0|      40348.79|      0|             0|\n",
      "|   1|   DEBIT|  9644.94|       4465.0|           0.0|       10845.0|     157982.12|      0|             0|\n",
      "|   1| PAYMENT|  3099.97|      20771.0|      17671.03|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  2560.74|       5070.0|       2509.26|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 11633.76|      10127.0|           0.0|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  4098.78|     503264.0|     499165.22|           0.0|           0.0|      0|             0|\n",
      "|   1|CASH_OUT|229133.94|      15325.0|           0.0|        5083.0|      51513.44|      0|             0|\n",
      "|   1| PAYMENT|  1563.82|        450.0|           0.0|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  1157.86|      21156.0|      19998.14|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|   671.64|      15123.0|      14451.36|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER| 215310.3|        705.0|           0.0|       22425.0|           0.0|      0|             0|\n",
      "+----+--------+---------+-------------+--------------+--------------+--------------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "521dc20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|    type| count|\n",
      "+--------+------+\n",
      "|TRANSFER| 82424|\n",
      "| CASH_IN|218673|\n",
      "|CASH_OUT|362676|\n",
      "| PAYMENT|329752|\n",
      "|   DEBIT|  6474|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# View and group the data by “type” as follows:\n",
    "df.groupby(\"type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1073f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|isFraud| count|\n",
      "+-------+------+\n",
      "|      0|999464|\n",
      "|      1|   535|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Explore the number of fraud cases.\n",
    "df.groupby(\"isFraud\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e60b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for string indexing.\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd99efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function for string indexer.\n",
    "si = StringIndexer(inputCol=\"type\", outputCol=\"type_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70354354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply required transformation on dataframe.\n",
    "df_indexed = si.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5534f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-------------+--------------+--------------+--------------+-------+--------------+----------+\n",
      "|step|    type|  amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|type_index|\n",
      "+----+--------+--------+-------------+--------------+--------------+--------------+-------+--------------+----------+\n",
      "|   1| PAYMENT| 9839.64|     170136.0|     160296.36|           0.0|           0.0|      0|             0|       1.0|\n",
      "|   1| PAYMENT| 1864.28|      21249.0|      19384.72|           0.0|           0.0|      0|             0|       1.0|\n",
      "|   1|TRANSFER|   181.0|        181.0|           0.0|           0.0|           0.0|      1|             0|       3.0|\n",
      "|   1|CASH_OUT|   181.0|        181.0|           0.0|       21182.0|           0.0|      1|             0|       0.0|\n",
      "|   1| PAYMENT|11668.14|      41554.0|      29885.86|           0.0|           0.0|      0|             0|       1.0|\n",
      "+----+--------+--------+-------------+--------------+--------------+--------------+-------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# View the new df.\n",
    "df_indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "516bdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for one-hot encoder.\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4039461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function for one-hot encoder.\n",
    "encoder = OneHotEncoder(inputCols=[\"type_index\"], outputCols=[\"type_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71dc1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform your dataframe with the encoded data.\n",
    "df_enc = encoder.fit(df_indexed)\n",
    "df_encoded = df_enc.transform(df_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7bfe3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------+-------------+--------------+--------------+--------------+-------+--------------+----------+-------------+\n",
      "|step|    type| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|type_index| type_encoded|\n",
      "+----+--------+-------+-------------+--------------+--------------+--------------+-------+--------------+----------+-------------+\n",
      "|   1| PAYMENT|9839.64|     170136.0|     160296.36|           0.0|           0.0|      0|             0|       1.0|(4,[1],[1.0])|\n",
      "|   1| PAYMENT|1864.28|      21249.0|      19384.72|           0.0|           0.0|      0|             0|       1.0|(4,[1],[1.0])|\n",
      "|   1|TRANSFER|  181.0|        181.0|           0.0|           0.0|           0.0|      1|             0|       3.0|(4,[3],[1.0])|\n",
      "+----+--------+-------+-------------+--------------+--------------+--------------+-------+--------------+----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# View the new df.\n",
    "df_encoded.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67011e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for vector assembler\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8c3939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns required.\n",
    "selected_cols=['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest','type_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e4c4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the vector assembler function and save it into a new dataframe.\n",
    "va = VectorAssembler(inputCols=selected_cols,outputCol=\"features\")\n",
    "df_vectors = va.transform(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b690053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-------------+--------------+--------------+--------------+-------+--------------+----------+-------------+--------------------+\n",
      "|step|    type|  amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|type_index| type_encoded|            features|\n",
      "+----+--------+--------+-------------+--------------+--------------+--------------+-------+--------------+----------+-------------+--------------------+\n",
      "|   1| PAYMENT| 9839.64|     170136.0|     160296.36|           0.0|           0.0|      0|             0|       1.0|(4,[1],[1.0])|(10,[0,1,2,3,7],[...|\n",
      "|   1| PAYMENT| 1864.28|      21249.0|      19384.72|           0.0|           0.0|      0|             0|       1.0|(4,[1],[1.0])|(10,[0,1,2,3,7],[...|\n",
      "|   1|TRANSFER|   181.0|        181.0|           0.0|           0.0|           0.0|      1|             0|       3.0|(4,[3],[1.0])|(10,[0,1,2,9],[1....|\n",
      "|   1|CASH_OUT|   181.0|        181.0|           0.0|       21182.0|           0.0|      1|             0|       0.0|(4,[0],[1.0])|(10,[0,1,2,4,6],[...|\n",
      "|   1| PAYMENT|11668.14|      41554.0|      29885.86|           0.0|           0.0|      0|             0|       1.0|(4,[1],[1.0])|(10,[0,1,2,3,7],[...|\n",
      "+----+--------+--------+-------------+--------------+--------------+--------------+-------+--------------+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_vectors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfa38df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into test and train data.\n",
    "(trainingData, testData) = df_vectors.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d1e7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the decision tree classifier function.\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"isFraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "930c7f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the training data.\n",
    "model = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a17b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d2b329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+\n",
      "|prediction|isFraud|            features|\n",
      "+----------+-------+--------------------+\n",
      "|       0.0|      0|[1.0,270.78,41849...|\n",
      "|       0.0|      0|[1.0,783.31,81503...|\n",
      "|       0.0|      0|[1.0,1076.27,3538...|\n",
      "|       0.0|      0|[1.0,2673.64,7688...|\n",
      "|       0.0|      0|[1.0,4865.48,7395...|\n",
      "+----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# View the resultant dataframe to analyse better.\n",
    "predictions.select(\"prediction\", \"isFraud\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72bc9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries.\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15e9c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluator function.\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"isFraud\",\n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49a856d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996596289956052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# View the accuracy.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff20b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries.\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c53d6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: need to cast to float type, and order by prediction, else it won't work:\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','isFraud']) \\\n",
    "                    .withColumn('label', F.col('isFraud').cast(FloatType())).orderBy('prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00b7f67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/spark-3.3.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/context.py:159: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Select only prediction and label columns\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcd0d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[299484.     41.]\n",
      " [    61.     87.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ae296ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision for label 0\n",
    "precision0 = metrics.precision(0)\n",
    "\n",
    "# Recall for label 0\n",
    "recall0 = metrics.recall(0)\n",
    "\n",
    "# Precision for label 1\n",
    "precision1 = metrics.precision(1)\n",
    "\n",
    "# Recall for label 1\n",
    "recall1 = metrics.recall(1)\n",
    "\n",
    "# F1 score for label 0\n",
    "f1Score0 = metrics.fMeasure(0.0, beta = 1.0)\n",
    "\n",
    "# F1 score for label 1\n",
    "f1Score1 = metrics.fMeasure(1.0, beta = 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
