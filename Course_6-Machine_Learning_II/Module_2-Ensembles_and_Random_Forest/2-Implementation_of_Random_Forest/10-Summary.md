# Summary

You have now reached the end of the first session of the module. In the next video, let's summarise your learnings.

**VIDEO**

This session covered the following:

-   First, you learnt how to interpret the results of the random forest model in terms of feature importance. Even though the metric deos not provide the flow of impact, it helps you to identify the factor that is key in the decision-making process.

![Feature Importance Weighted Average](https://i.ibb.co/P9RSmyX/Feature-Importance-Weighted-Average-2.jpg)

-   Next, you learnt how to build a random forest model in Python for a classification problem. You dealt with the problem of heart disease prediction in this case study.  
     

![Random Forest Heart Disease Prediction](https://i.ibb.co/2jvYT0S/Random-Forest-Heart-Disease-Prediction.jpg)

-   After the classification problem, you came across the problem of house price prediction.
-   Later, you went through the telecom churn case study in which we compared all the classification models covered so far.
-   After the model building process, you learnt how random forest deals with missing values and outliers. It uses a proximity matrix to overcome the missing values and remains unaffected by the outliers owing to bagging.     

![Proximity Score Matrix](https://i.ibb.co/pxgpbj4/Proximity-Score-Matrix.jpg)

-   Finally, you learnt how there is a trade-off between the model building time and the optimisation performed using the hyperparameters. 

In the next session, you will learn how to run this algorithm in the Spark environment.