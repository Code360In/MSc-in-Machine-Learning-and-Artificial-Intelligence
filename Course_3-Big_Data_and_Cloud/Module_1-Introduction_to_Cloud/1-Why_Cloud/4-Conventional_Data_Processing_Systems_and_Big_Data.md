# Conventional Data Processing Systems and Big Data

So far, you learnt the characteristics of big data and its industrial applications. However, it is important for you to know the exact issues surrounding traditional data-processing systems, and the reasons why these systems cannot process big data. Mr Shankaran will teach you more about this in the lecture below.

**VIDEO**

To summarise, traditional systems cannot handle big data because of the following reasons:

- **Volume:** They cannot store gigantic amounts of data such as data in terabytes or petabytes.
- **Variety:** They can only store and process structured data, not unstructured data.
- **Velocity:** Traditional systems are not suited to processing data in real time at high speeds, which big data systems such as Spark are able to do.
- **Veracity:** Since unstructured data is often collected from external sources and has questionable quality and validity, big data systems need to identify these issues while ingesting and processing the data.

#### Conventional vs Big Data Processing

Qn: Pick the scenario that cannot be managed using a traditional system such as an RDBMS.

- Storing data in the row-and-column format

- Storing data in any format or schema in the storage space

- Aggregating data using aggregation features such as sum(), mean(), avg, etc.

- Selecting specific records from a dataset, based on a filter condition

Ans: B. *An RDBMS always stores data in the row-and-column format and follows a strict schema. If the data being inserted doesn’t follow the format, then the data insertion fails.*

You now have a fair understanding of why traditional systems are incapable of storing and processing big data. Also, you learnt, from a few case studies, how big data is used to derive valuable insights that will help in decision-making. Now, let's dive into the world of big data. In the upcoming segments, you will learn about big data systems and cloud computing in detail.
