# Introduction

Catalyst Optimiser, as you learnt in the previous session, is a powerful built-in functionality in SparkSQL. It generates a logical plan, optimises it, and uses the cost model to choose the least-costing model.Â Finally, the Optimiser converts it to lower-level instructions. The working of Spark can be visualised using SparkUI, which offers insights into the actual working of the Catalyst Optimiser.

## In this session

In the previous session, you learnt about the capabilities of PySpark and the different built-in functionalities of Spark for faster processing of data. Apart from all these features, what truly makes Spark powerful is its universality. In this session, you will learn how to read data from different data sources using Spark.

Different abstractions in spark provide different functionalities. So, after reading the data, the next important step is to decide which API and coding paradigm to use. In this session, you will explore the factors that affect this decision.

## People you will hear from in this session

**Subject matter expert**

**[Sajan Kedia](https://in.linkedin.com/in/sajan-kedia-b06a6821)**

Data Science Lead - Myntra

Sajan has completed his undergraduate and postgraduate in Computer Science Engineering from IIT, BHU. He heads the pricing team at Myntra, where he actively works on technologies like Data Science, Big Data, Spark and Machine learning. Presently, his work mainly involves the development of discounting strategies for all the products offered by Myntra.
