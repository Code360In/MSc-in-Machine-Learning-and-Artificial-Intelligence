# Introduction

Welcome to the session on ‘Basic EDA using Spark ML library’. 

So far in the previous sessions of the module, you have learnt about spark structures APIs: data frames and data sets. The module focused on data frames, as the main data structure. After that, the module focused on the internal optimiser for structured APIs- the catalyst optimiser. The discussion about the working of the optimiser started with the architecture of the optimiser and then the actual execution of the optimiser was demonstrated with through Spark UI. Finally, you see the different sources in which the data can be read into the spark environment. 

## In this Session

In this session, you will first explore the Spark ML API  and understand how to perform basic EDA on a dataset. You will understand components such as feature transformers, feature estimators, pipelines and their usage while writing your codes in PySpark. In the upcoming modules of the program, you would take references of various feature transformers and feature extractors while building machine learning models. 


## People you will hear from in this module

**Subject Matter Expert**

[Ankit Agarwal](https://www.linkedin.com/in/ankit-agarwal-4333248/)

**AI-COE, Reliance Jio**

Ankit has over 12 years of experience in machine learning and AI across different domains such as banking and financial services, e-commerce and telecom. He has worked with Amazon, Snapdeal and Citigroup.

He is an expert in the application of ML in marketing and risk. He has worked with organisations across multiple geographies and developed and implemented data science solutions targeting different stages in the customer life cycle. He has worked extensively on building ML models and has experience in advanced techniques such as neural networks, GBMs and SVMs.