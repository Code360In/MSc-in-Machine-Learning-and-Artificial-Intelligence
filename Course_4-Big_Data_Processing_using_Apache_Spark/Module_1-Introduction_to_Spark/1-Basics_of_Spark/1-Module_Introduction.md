# Module Introduction

In the previous course, you learnt about Apache Hadoop and understood how useful it is for handling Big Data. Due to its enormous size, big data requires different infrastructure for storage and processing as compared with traditional systems such as Relational Database Management Systems (RDBMS). Apache Hadoop provides the required infrastructure in the form of HDFS for distributed storage and MapReduce for distributed processing.

However, MapReduce is unable to meet the requirements arising from the rapid growth of data. One of the major requirements in day-to-day business scenarios is the **quick analysis** of big data. For example, Uber, a ride-sharing app, receives data from its drivers and booking-related data from its users through the platform, and then calculates the approximate fare for each trip based on supply and demand. Even though MapReduce is highly scalable and fault-tolerant, it cannot deliver the output this quickly. Other similar examples that require faster processing include flight bookings and recommendation engines.

This has led to the development of a new processing framework, Apache Spark, which has gained great popularity in a very short period of time. Since its development in 2013, global giants such as Amazon, Alibaba, Yahoo and Uber have been using Spark extensively in their production environments. In this course, you will learn about Apache Spark and understand its merits over MapReduce for Big Data analytics.  

## In this module

The first module in the course on Apache Spark is called ‘**Introduction to Spark**’. Let’s hear our industry expert as he provides an overview of the topics that will be covered in this module.

**VIDEO**

Apache Spark helps you process and analyse big data in a distributed framework. As mentioned in the video above, the following topics will be covered in this module:

- Basic features of Apache Spark
- How these features help Spark surpass MapReduce
- Internals of the Spark architecture
- The core abstraction of Spark: Resilient Distributed Dataset (RDD)

By the end of this module, you should be able to perform basic functions in Spark using the core component of Spark, i.e., RDDs.

## In this session

The first session titled 'Basics of Spark' deals with the theoretical concepts of Spark. You will learn how the Spark framework is different from the Hadoop MapReduce. You will also learn about the wide range of features offered in the Spark framework during the course of this session.

## People you will hear from in this session

**Subject matter experts**  
**[Janakiram D](https://www.iitm.ac.in/info/fac/djram)**  
Professor, IIT Madras  
Dharanipragada Janakiram completed his PhD from IIT Delhi and is currently a professor in the Department of Computer Science and Engineering, IIT Madras, where he heads and coordinates the research activities of the Distributed and Object Systems Lab. He was awarded the IBM Faculty Award in 2007 and the Yahoo Faculty Grant in 2009. He has guided 14 PhD students, over 36 MS (research) students and 70 MTech students. He has authored over 150 research papers and is the editor of six books. The Minimalistic Object Oriented Linux (MOOL) OS developed by him along with his students at the DOS lab is being distributed by CDAC as part of Bharat Operating System and Solutions (BOSS).

**[Sajan Kedia](https://in.linkedin.com/in/sajan-kedia-b06a6821)**  
Data Scientist, Myntra  
Sajan has completed his undergraduate and postgraduate degrees in Computer Science Engineering from IIT, BHU. He heads the pricing team at Myntra, where he actively works on technologies such as Data Science, Big Data, Spark and Machine learning. Currently, his work mainly involves the development of discounting strategies for all the products offered by Myntra.
